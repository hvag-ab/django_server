关于Django多进程多线程详解

django runserver 是单进程多线程模式启动。

uWSGI默认是单进程单线程
uwsgi --http 0.0.0.0:8000 --file Demo/wsgi.py --processes 4 --threads 2
# processes: 进程数 # processes 和 workers 一样的效果
# threads : 每个进程开的线程数

uwsgi是一个优秀的web server, 但是出于性能和安全性的考虑, 往往会在uwsgi上面再包一层Nginx。
而Nginx是一个异步多进程的服务器, 所以在使用中往往会fork多个nginx的worker进程, 来提高处理request的效率。
worker进程数一般是cpu核心数。


场景1：

2个进程，每个进程1个线程，请求函数中设置了10秒sleep，9个请求同一URL：

结果：

1. 全局变量ID值，在每一个进程中相同，不同进程中不相同

2. 并行只能接受2个请求，同时发起多个请求，则需要排队等待处理

场景2：

1个进程，每个进程2个线程，请求函数中设置了10秒sleep，9个请求同一URL：

结果：

1. 全局变量ID值，在单进程中相同，每个线程中也相同

2. 并行只能接收2个请求，同时发起多个请求，则需要排队等待处理

场景3：

2个进程，每个进程2个线程，请求函数中设置了10秒sleep，9个请求同一URL：

结果：

1. 全局变量ID值，在每一个进程中相同，同一进程中每个线程中也相同，不同进程中不相同

2. 并行只能接收4 ( 2进程* 2 线程 ) 个请求，同时发起多个请求，则需要排队等待处理

总结：

1. 每个WSGI进程会拥有独立的python变量，该进程内线程共享该变量

2. 进程数 乘以 线程数得到同时能够处理的并发请求数

3. 一个固定的线程，正在处理一个请求时，请求未处理结束，不会同时处理另外的请求。


关于单例模式：
问题：单例模式在本地测试时一切正常，当运行在生产环境下，单例不生效，会创建出多个实例。

原因：Django/Flask本地环境的runserver为单进程多线程，单进程下当然共享一份内存，而在生产环境的多worker下，每个进程都有自己的内存空间，因此也有自己的实例。

关于全局变量：
同样的问题，在生产环境中，多个worker之间是无法共享一个全局变量的，一个worker修改了这个变量，其他worker是看不到改变后的结果的。

如果需要共享数据，应该使用数据库或者单独的缓存服务器。

当uwsgi使用master-worker的方式启动多个Django Application，各进程之间互相隔离，将全局变量写在view当中会导致各进程间不一致 view是一个类or函数 实例后运行就释放内存了 变量就是局部变量了。
uwsgi将django项目读取一次之后,在master进程完成初始化, 包括我们设置的全局变量的代码块. 之后获取request直接在master中进行fork().这也是所谓preforking模式, 可以保证运行过程当中不需要再从磁盘读取代码文件.

注：
fork 含义
一个现有进程可以调用fork函数创建一个新进程。由fork创建的新进程被称为子进程（child process）。fork函数被调用一次但返回两次。两次返回的唯一区别是子进程中返回0值而父进程中返回子进程ID。
子进程是父进程的副本，它将获得父进程数据空间、堆、栈等资源的副本。注意，子进程持有的是上述存储空间的“副本”，这意味着父子进程间不共享这些存储空间。
UNIX将复制父进程的地址空间内容给子进程，因此，子进程有了独立的地址空间。在不同的UNIX (Like)系统下，我们无法确定fork之后是子进程先运行还是父进程先运行，这依赖于系统的实现


例子：
用户第一次登陆成功后将用户信息保存到一个全局变量，后面登陆其他页面直接从全局变量中获取已保存的信息 出现获取不到保存的信息
我们都知道线程属于进程，同一个进程里的线程之间可以相互访问内存，而不同进程之间的内存是隔离的（每个进程都启动了独立的django环境），例如启用了四个进程，第一个用户访问的时候调用一个进程，第二个用户访问时可能新启动了一个进程，所以导致程序无法获取到第一次生成的全局变量


补充：

使用execute_from_command_line(django自带runserver)方式启动django应用时, 会先加载urls, 从而会加载我们写的业务代码(views中的代码); 然后再加载中间件代码. 在应用启动完成时, 所有相关代码都已经被加载入内存。

使用get_wsgi_application(uwisg或gunicorn)方式启动django应用时, 会先加载中间件代码, 这与上面完全相反。 此时, 我们的业务代码仍然没有被加载, 直到第一个请求过来。 如果我们在代码中, 使用了未加载的代码中的全局变量, 就会出现莫名其妙的bug

生产环境下，一般都会设置多个worker（进程），中间件在master进程中加载完成后, 才开始fork子进程, 所以，切勿在中间件中写block的代码, 万一deadlock, 整个服务就挂了。 其实这也是符合Nginx的设计理念的, Nginx的master进程负责处理request信息, 包括处理处理起始行、提取头部、负载等, 然后把请求随机下发到worker进程。同样的, django的中间件也是处理request的, 包括加载session等等。 所以应该把中间件代码放在master进程。

启动时，所有的worker进程都会加载我们的业务代码。 如果某个worker进程, 没有加载过业务代码, 那么当有一个request被下发给它时, 就会去加载。

由于每个worker进程都会加载一次我们的views代码, 那么就会产生一个问题。如果我们在全局的位置, 做了一些特殊的操作， 比如说开了一个线程, 或者定义一把全局锁, 那么, 在生产环境多进程下, 就会发生, 每个进程都开了一个线程, 或者每个进程都有自己的锁。 之前就遇到过一个bug, 全局位置开了线程去轮询某个资源, 然后写入数据库, 部署到Nginx后, 发现每个item都被写了4次......

还要注意，这些worker之间并不会共享全局变量，在worker A中的修改不会同步到worker B, 必然会出bug

一个worker(进程)可以拥有多个线程，每个线程使用其所属进程的栈空间。同一进程内的多个线程会共享部分状态，多个线程可以读写同一块内存（一个进程无法直接访问另一进程的内存）。同时，每个线程还拥有自己的寄存器和栈，其他线程可以读写这些栈内存。

一份全局变量只存在于一个python进程中,这个python进程下的子进程可以通过python自带的multiprocess提供的value和array方法共享全局变量。子进程继承父进程的全局变量，而且是以复制的形式完成，所以子进程修改后的全局变量只对自己和自己的子进程有影响。父子进程不共享这些全局变量，也就是说：父进程中对全局变量的修改不影响子进程中的全局变量，同理，子进程也不影响父进程的。

uwisg或gunicorn的多worker（进程）与python的一个进程下的多个子进程不是一个层面上的，后者子进程可以通过multiprocess共享全局变量，前者做不到。



并行和并发的区别：

并发，指的是多个事情，在同一时间段内同时发生了。
并行，指的是多个事情，在同一时间点上同时发生了。

并发的多个任务之间是互相抢占资源的。
并行的多个任务之间是不互相抢占资源的、

只有在多CPU或者一个CPU多核的情况中，才会发生并行。否则，看似同时发生的事情，其实都是并发执行的。

多进程的多处理器的python应用可能存在并行,至于并发还是并行,有操作系统决定,如果分配单处理器处理多进程,
那就是并发,如果分配给多处理器那就是并行
