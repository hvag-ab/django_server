使用更多的queue（不要只用默认的）
Celery非常容易设置，通常它会使用默认的queue用来存放任务（除非你显示指定其他queue）。通常写法如下：

    @app.task()
    def my_taskA(a, b, c):
        print("doing something here...")

    @app.task()
    def my_taskB(x, y):
        print("doing something here...")
这两个任务都会在同一个queue里面执行，这样写其实很有吸引力的，因为你只需要使用一个decorator就能实现一个异步任务。作者关心的是taskA和taskB没准是完全两个不同的东西，或者一个可能比另一个更加重要，
那么为什么要把它们放到一个篮子里面呢？（鸡蛋都不能放到一个篮子里面，是吧！）没准taskB其实不怎么重要，但是量太多，
以至于重要的taskA反而不能快速地被worker进行处理。增加workers也解决不了这个问题，
因为taskA和taskB仍然在一个queue里面执行。

3:使用具有优先级的workers
为了解决2里面出现的问题，我们需要让taskA在一个队列Q1，而taskB在另一个队列Q2执行。
同时指定x workers去处理队列Q1的任务，然后使用其它的workers去处理队列Q2的任务。
使用这种方式，taskB能够获得足够的workers去处理，同时一些优先级workers也能很好地处理taskA而不需要进行长时间的等待。

首先手动定义queue
from kombu import Exchange, Queue

CELERY_QUEUES = (
    Queue('default', Exchange('default'), routing_key='default'),
    Queue('for_task_A', Exchange('for_task_A'), routing_key='for_task_A'),
    Queue('for_task_B', Exchange('for_task_B'), routing_key='for_task_B'),
)
然后定义routes用来决定不同的任务去哪一个queue

CELERY_ROUTES = {
    'my_taskA': {'queue': 'for_task_A', 'routing_key': 'for_task_A'},
    'my_taskB': {'queue': 'for_task_B', 'routing_key': 'for_task_B'},
}

最后再为每个task启动不同的

celery worker -E -l INFO -n workerA -Q for_task_A celery worker -E -l INFO -n workerB -Q for_task_B
如果在我们项目中，会涉及到大量文件转换问题，有大量小于1mb的文件转换，同时也有少量将近20mb的文件转换，
小文件转换的优先级是最高的，同时不用占用很多时间，但大文件的转换很耗时。如果将转换任务放到一个队列里面，
那么很有可能因为出现转换大文件，导致耗时太严重造成小文件转换延时的问题。

也可以下面这种设置
显然是并发的。-c参数定义工作者创建的并发线程数。

(venv) $ celery -A proj worker -l info -Q default -c 2
(venv) $ celery -A proj worker -l info -Q low_priority -c 1
(venv) $ celery -A proj worker -l info -Q high_priority -c 4
并具有自动缩放工人

(venv) $ celery -A proj worker -l info -Q default --autoscale 4,2
(venv) $ celery -A proj worker -l info -Q low_priority --autoscale 2,1
(venv) $ celery -A proj worker -l info -Q high_priority --autoscale 8,4
这样，您可以控制任务的消耗速度。

并发数应保持接近CPU核心数。如果服务器具有4个核心CPU，则最大并发数应为4。当然，更大的数字将起作用，但效率较低。

任务延迟的第一个也是最简单的方法是使用countdown参数。倒数时间为Int，代表以秒表示的延迟时间。

my_task.apply_async(countdown=10)
优点
使用方便
可读的
缺点
enable_utc设置为False并且定义了时区时不起作用
预计到达时间
第二种方法是使用eta参数，它需要执行的确切日期和时间。与本机datetime对象，日期为String或Pendulum实例完美配合。

my_task.apply_async(eta=datetime.now(pytz.timezone("Europe/Warsaw"))
my_task.apply_async(eta="2018-02-19 13:41:14+01:00")
my_task.apply_async(eta=pendulum.now("Europe/Warsaw"))
